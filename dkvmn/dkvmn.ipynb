{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PREFIX = 'dataset_'\n",
    "\n",
    "params = {\n",
    "    'max_iter': 2, # 'number of iterations'\n",
    "    'show': True, # 'print progress')\n",
    "    'init_std': 0.1, # 'weight initialization std'\n",
    "    'init_lr': 0.01, # 'initial learning rate'\n",
    "    'lr_decay': 0.75, # 'learning rate decay'\n",
    "    'final_lr': 1E-5, # 'learning rate will not decrease after hitting this threshold'\n",
    "    'momentum': 0.9, # 'momentum rate'\n",
    "    'maxgradnorm': 50.0, # 'maximum gradient norm'\n",
    "    'final_fc_dim': 50, # 'hidden state dim for final fc layer'\n",
    "    'key_embedding_dim': 50, # 'question embedding dimensions')\n",
    "    'batch_size': 64, # 'the batch size')\n",
    "    'value_embedding_dim': 200, # 'answer and question embedding dimensions')\n",
    "    'memory_size': 20, # 'memory size')\n",
    "    'n_question': 9, # 'the number of unique questions in the dataset')\n",
    "    'seqlen': 200, # 'the allowed maximum length of a sequence')\n",
    "    'data_dir': '../', # 'data directory')\n",
    "    'data_name': '', # 'data set name')\n",
    "    'load': FILE_PREFIX + 'dkvmn.params', # 'model file to load')\n",
    "    'save': FILE_PREFIX + 'dkvmn.params' # 'path to save model')\n",
    "}\n",
    "\n",
    "params['lr'] = params['init_lr']\n",
    "params['key_memory_state_dim'] = params['key_embedding_dim']\n",
    "params['value_memory_state_dim'] = params['value_embedding_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import Data\n",
    "\n",
    "dat = Data(n_question=params['n_question'], seqlen=params['seqlen'], separate_char=',') \n",
    "\n",
    "train_data_path = params['data_dir'] + \"/\" + params['data_name'] + FILE_PREFIX + \"train.txt\"\n",
    "test_data_path = params['data_dir'] + \"/\" + params['data_name'] + FILE_PREFIX + \"test.txt\"\n",
    "train_data = dat.load_data(train_data_path)\n",
    "test_data = dat.load_data(test_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EduKTM import DKVMN\n",
    "\n",
    "model = DKVMN(n_question=params['n_question'],\n",
    "                batch_size=params['batch_size'],\n",
    "                key_embedding_dim=params['key_embedding_dim'],\n",
    "                value_embedding_dim=params['value_embedding_dim'],\n",
    "                memory_size=params['memory_size'],\n",
    "                key_memory_state_dim=params['key_memory_state_dim'],\n",
    "                value_memory_state_dim=params['value_memory_state_dim'],\n",
    "                final_fc_dim=params['final_fc_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 227/227 [00:36<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, loss : 0.47460, auc : 0.67162, accuracy : 0.79589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 227/227 [00:39<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, loss : 0.46579, auc : 0.69194, accuracy : 0.79639\n"
     ]
    }
   ],
   "source": [
    "model.train(params, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(params['save'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 96/96 [00:09<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid auc : 0.69275, valid accuracy : 0.79490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4670858650157849, 0.7949034598742039, np.float64(0.6927475560952349))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load(params['load'])\n",
    "model.eval(params, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from EduKTM import DKVMN\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_iter': 10, # 'number of iterations'\n",
    "        'show': False, # 'print progress')\n",
    "        'init_std': trial.suggest_float('init_std', 0.01, 0.2), # 'weight initialization std'\n",
    "        'init_lr': trial.suggest_float('init_lr', 0.001, 0.1), # 'initial learning rate'\n",
    "        'lr_decay': trial.suggest_float('lr_decay', 0.5, 0.99), # 'learning rate decay'\n",
    "        'final_lr': trial.suggest_float('final_lr', 1E-6, 1E-4), # 'learning rate will not decrease after hitting this threshold'\n",
    "        'momentum': trial.suggest_float('momentum', 0.5, 0.99), # 'momentum rate'\n",
    "        'maxgradnorm': trial.suggest_float('maxgradnorm', 10.0, 100.0), # 'maximum gradient norm'\n",
    "        # 'final_fc_dim': 50, # 'hidden state dim for final fc layer'\n",
    "        # 'key_embedding_dim': 50, # 'question embedding dimensions')\n",
    "        'batch_size': 64, # 'the batch size')\n",
    "        'value_embedding_dim': trial.suggest_int('value_embedding_dim', 50, 500), # 'answer and question embedding dimensions')\n",
    "        'memory_size': trial.suggest_int('memory_size', 10, 100), # 'memory size')\n",
    "        'n_question': 123, # 'the number of unique questions in the dataset')\n",
    "        'seqlen': 200, # 'the allowed maximum length of a sequence')\n",
    "        'data_dir': '../dkt', # 'data directory')\n",
    "        'data_name': '', # 'data set name')\n",
    "    }\n",
    "    \n",
    "    params['final_fc_dim'] = params['key_embedding_dim'] = trial.suggest_int('final_fc_dim', 10, 100) # 'hidden state dim for final fc layer'\n",
    "    \n",
    "    params['lr'] = params['init_lr']\n",
    "    params['key_memory_state_dim'] = params['key_embedding_dim']\n",
    "    params['value_memory_state_dim'] = params['value_embedding_dim']\n",
    "\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = DKVMN(n_question=params['n_question'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    key_embedding_dim=params['key_embedding_dim'],\n",
    "                    value_embedding_dim=params['value_embedding_dim'],\n",
    "                    memory_size=params['memory_size'],\n",
    "                    key_memory_state_dim=params['key_memory_state_dim'],\n",
    "                    value_memory_state_dim=params['value_memory_state_dim'],\n",
    "                    final_fc_dim=params['final_fc_dim'])\n",
    "    \n",
    "    # Train and evaluate\n",
    "    model.train(params, train_data)\n",
    "    loss, auc, accuracy = model.eval(params, test_data)\n",
    "    \n",
    "    return auc  # Optimize for AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run the study\n",
    "study = optuna.create_study(study_name=FILE_PREFIX+\"dkvmn_importances\", direction='maximize', storage=\"sqlite:///../studies.db\", load_if_exists=True)\n",
    "study.optimize(objective, n_trials=24, n_jobs=8)  # Adjust number of trials as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value (AUC): {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the importance of hyperparameters\n",
    "param_importance = optuna.importance.get_param_importances(study)\n",
    "print(\"\\nParameter importance:\")\n",
    "for param, importance in param_importance.items():\n",
    "    print(f\"  {param}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from EduKTM import DKVMN\n",
    "\n",
    "def refined_objective(trial):\n",
    "    # Only optimize the most important parameters based on previous study\n",
    "    refined_params = {\n",
    "        'max_iter': 10,\n",
    "        'show': False, # 'print progress')\n",
    "        'init_std': 0.1064392520682464, # 'weight initialization std'\n",
    "        'lr_decay': 0.8769705774588257, # 'learning rate decay'\n",
    "        'final_lr': 3.0584517647771867E-05, # 'learning rate will not decrease after hitting this threshold'\n",
    "        'final_fc_dim': 76, # 'hidden state dim for final fc layer'\n",
    "        'key_embedding_dim': 76, # 'question embedding dimensions')\n",
    "        'batch_size': 64, # 'the batch size')\n",
    "        'value_embedding_dim': 226, # 'answer and question embedding dimensions')\n",
    "        'memory_size': 65, # 'memory size')\n",
    "        'n_question': 123, # 'the number of unique questions in the dataset')\n",
    "        'seqlen': 200, # 'the allowed maximum length of a sequence')\n",
    "        'data_dir': '../dkt', # 'data directory')\n",
    "        'data_name': '', # 'data set name')\n",
    "    }\n",
    "    \n",
    "    # Only optimize the top 3 most important parameters\n",
    "    refined_params['init_lr'] = trial.suggest_float('init_lr', 0.01, 0.05)  # Narrow range around best value\n",
    "    refined_params['maxgradnorm'] = trial.suggest_float('maxgradnorm', 50.0, 100.0)  # Narrow range around best value\n",
    "    refined_params['momentum'] = trial.suggest_float('momentum', 0.5, 0.8)  # Narrow range around best value\n",
    "    \n",
    "    refined_params['lr'] = refined_params['init_lr']\n",
    "    refined_params['key_memory_state_dim'] = refined_params['key_embedding_dim']\n",
    "    refined_params['value_memory_state_dim'] = refined_params['value_embedding_dim']\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = DKVMN(n_question=refined_params['n_question'],\n",
    "                  batch_size=refined_params['batch_size'],\n",
    "                  key_embedding_dim=refined_params['key_embedding_dim'],\n",
    "                  value_embedding_dim=refined_params['value_embedding_dim'],\n",
    "                  memory_size=refined_params['memory_size'],\n",
    "                  key_memory_state_dim=refined_params['key_memory_state_dim'],\n",
    "                  value_memory_state_dim=refined_params['value_memory_state_dim'],\n",
    "                  final_fc_dim=refined_params['final_fc_dim'])\n",
    "    \n",
    "    # Train and evaluate\n",
    "    model.train(refined_params, train_data)\n",
    "    loss, auc, accuracy = model.eval(refined_params, test_data)\n",
    "    \n",
    "    return auc  # Optimize for AUC\n",
    "\n",
    "# Create and run the refined study\n",
    "refined_study = optuna.create_study(study_name=FILE_PREFIX+\"dkvmn_refined\", \n",
    "                                   direction='maximize', \n",
    "                                   storage=\"sqlite:///../studies.db\", \n",
    "                                   load_if_exists=True)\n",
    "refined_study.optimize(refined_objective, n_trials=12, n_jobs=4)\n",
    "\n",
    "# Print results\n",
    "print(\"Best refined trial:\")\n",
    "refined_trial = refined_study.best_trial\n",
    "print(f\"  Value (AUC): {refined_trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in refined_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_iter': 50,\n",
    "    'show': True, # 'print progress')\n",
    "    'init_std': trial.params['init_std'], # 'weight initialization std'\n",
    "    'init_lr': trial.params['init_lr'], # 'initial learning rate'\n",
    "    'lr_decay': trial.params['lr_decay'], # 'learning rate decay'\n",
    "    'final_lr': trial.params['final_lr'], # 'learning rate will not decrease after hitting this threshold'\n",
    "    'momentum': trial.params['momentum'], # 'momentum rate'\n",
    "    'maxgradnorm': trial.params['maxgradnorm'], # 'maximum gradient norm'\n",
    "    'final_fc_dim': trial.params['final_fc_dim'], # 'hidden state dim for final fc layer'\n",
    "    'key_embedding_dim': trial.params['final_fc_dim'], # 'question embedding dimensions')\n",
    "    'batch_size': 64, # 'the batch size')\n",
    "    'value_embedding_dim': trial.params['value_embedding_dim'], # 'answer and question embedding dimensions')\n",
    "    'memory_size': trial.params['memory_size'], # 'memory size')\n",
    "    'n_question': 123, # 'the number of unique questions in the dataset')\n",
    "    'seqlen': 200, # 'the allowed maximum length of a sequence')\n",
    "    'data_dir': '../dkt', # 'data directory')\n",
    "    'data_name': '', # 'data set name')\n",
    "    'load': FILE_PREFIX + 'dkvmn.params', # 'model file to load')\n",
    "    'save': FILE_PREFIX + 'dkvmn.params' # 'path to save model')\n",
    "}\n",
    "\n",
    "params['lr'] = params['init_lr']\n",
    "params['key_memory_state_dim'] = params['key_embedding_dim']\n",
    "params['value_memory_state_dim'] = params['value_embedding_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EduKTM import DKVMN\n",
    "\n",
    "dkvmn = DKVMN(n_question=params['n_question'],\n",
    "                  batch_size=params['batch_size'],\n",
    "                  key_embedding_dim=params['key_embedding_dim'],\n",
    "                  value_embedding_dim=params['value_embedding_dim'],\n",
    "                  memory_size=params['memory_size'],\n",
    "                  key_memory_state_dim=params['key_memory_state_dim'],\n",
    "                  value_memory_state_dim=params['value_memory_state_dim'],\n",
    "                  final_fc_dim=params['final_fc_dim'])\n",
    "\n",
    "dkvmn.train(params, train_data)\n",
    "dkvmn.save(params['save'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkvmn.load(params['load'])\n",
    "dkvmn.eval(params, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
